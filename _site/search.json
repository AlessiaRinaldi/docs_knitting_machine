[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Automated Knitting Machine",
    "section": "",
    "text": "The idea behind this project draws inspiration from the operating principle of 3D printers: starting from a digital model, they can automatically produce three-dimensional objects with precision and repeatability.\nThe objective of this project is to transpose this paradigm to the textile field by developing an automated knitting machine capable of producing knit patterns from a predefined digital design."
  },
  {
    "objectID": "components.html",
    "href": "components.html",
    "title": "Components",
    "section": "",
    "text": "Key Components\n\nMotors, drivers, sensors\nCamera & lighting\nMCU & wiring"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "control-system.html",
    "href": "control-system.html",
    "title": "Control System",
    "section": "",
    "text": "Overview\n\nReal-time control loops\nVision-based thread detection\nSafety & states"
  },
  {
    "objectID": "error-recognition.html",
    "href": "error-recognition.html",
    "title": "Error Recognition",
    "section": "",
    "text": "The first step toward automating such an ancient and traditional technique is the ability to detect production errors in real time.\nAn integrated vision system must be able to identify the occurrence of anomalies (for example, missing yarn or skipped stitches), allowing the machine to intervene and stop the process before the defect fully develops, preventing serious errors and material waste."
  },
  {
    "objectID": "error-recognition.html#error-taxonomy",
    "href": "error-recognition.html#error-taxonomy",
    "title": "Error Recognition",
    "section": "",
    "text": "Missing thread: no yarn present during a stitch.\nThread break: yarn snapped or slack beyond tolerance.\nMis-stitch / skipped stitch: hook failed to catch/transfer the loop.\nJams / obstruction: mechanical interference preventing motion.\nBacklash / positioning drift: kinematic error causing misplaced stitches.\nLighting drift: exposure or color shift degrading vision accuracy."
  },
  {
    "objectID": "error-recognition.html#detection-pipeline-high-level",
    "href": "error-recognition.html#detection-pipeline-high-level",
    "title": "Error Recognition",
    "section": "",
    "text": "Sensing: camera frames + optional encoders / tension sensor.\nPreprocessing: crop, denoise, exposure normalization.\nInference: lightweight CNN / classical vision (edges, morphology).\nDecision logic: thresholds, temporal filtering, hysteresis.\nAction: warn, pause, retry, or safe-stop with guided recovery."
  },
  {
    "objectID": "error-recognition.html#dataset-labeling",
    "href": "error-recognition.html#dataset-labeling",
    "title": "Error Recognition",
    "section": "",
    "text": "Classes: {ok, missing_thread, break, mis_stitch, jam}.\nLabeling protocol: annotate bounding boxes/masks around hook & loop region; store frame index + machine state.\nSplit: train/val/test with subject and lighting stratification.\nAugmentations: brightness/contrast jitter, small blur, slight rotations."
  },
  {
    "objectID": "error-recognition.html#metrics",
    "href": "error-recognition.html#metrics",
    "title": "Error Recognition",
    "section": "",
    "text": "Per-class F1 and macro-F1 as primary.\nLatency (ms/frame), throughput (fps), false alarm rate (%/hr).\nMTTD (mean time to detection) for critical faults."
  },
  {
    "objectID": "error-recognition.html#runtime-deployment",
    "href": "error-recognition.html#runtime-deployment",
    "title": "Error Recognition",
    "section": "",
    "text": "Target: ‚â• 25‚Äì30 fps @ 320‚Äì640 px ROI.\nBudget: ‚â§ 25 ms inference, ‚â§ 10 ms I/O, ‚â§ 5 ms post-proc.\nFail-safe: if confidence &lt; threshold for N frames ‚Üí degrade to safe mode."
  },
  {
    "objectID": "error-recognition.html#requirements",
    "href": "error-recognition.html#requirements",
    "title": "Error Recognition",
    "section": "Requirements",
    "text": "Requirements\n\nShutter: global preferred (avoid motion artifacts on fast hooks).\nFrame rate: ‚â• 60 fps recommended; ‚â• 120 fps if fast cycles.\nResolution: enough to resolve the loop region (typically 320‚Äì800 px ROI on the hook).\nInterface: CSI (low latency) or USB3 (ubiquitous). GigE only if long cable runs.\nLens: C/CS-mount or M12 with suitable focal length; low distortion.\nLighting: diffuse LED ring or backlight; fixed CCT; flicker-free.\nSync: exposure synced to machine phase (encoder or GPIO trigger) if possible.\nMounting: rigid, vibration-damped, easy to re-calibrate."
  },
  {
    "objectID": "error-recognition.html#candidate-options-examples",
    "href": "error-recognition.html#candidate-options-examples",
    "title": "Error Recognition",
    "section": "Candidate Options (Examples)",
    "text": "Candidate Options (Examples)\n\nRaspberry Pi Camera (HQ / v3): CSI, low latency, good ecosystem; pick global shutter variant for fast motion.\nUSB3 industrial (e.g., IMX sensors): robust drivers, global shutter options, flexible lenses; slightly higher cost.\nLow-cost USB webcams: easy, but rolling shutter + auto-exposure can hurt reliability."
  },
  {
    "objectID": "error-recognition.html#decision-matrix-template",
    "href": "error-recognition.html#decision-matrix-template",
    "title": "Error Recognition",
    "section": "Decision Matrix (Template)",
    "text": "Decision Matrix (Template)\n\n\n\n\n\n\n\n\n\n\nCriterion\nWeight\nPi Cam (GS)\nUSB3 Industrial\nUSB Webcam\n\n\n\n\nLatency / Sync\n0.25\n4\n4\n2\n\n\nMotion artifacts (GS)\n0.25\n5\n5\n2\n\n\nImage quality / optics\n0.20\n4\n5\n3\n\n\nCost\n0.15\n4\n3\n5\n\n\nEase of integration\n0.15\n4\n4\n4\n\n\nWeighted score\n\n4.3\n4.4\n3.1\n\n\n\nScoring 1‚Äì5. Adjust weights to your constraints."
  },
  {
    "objectID": "error-recognition.html#recommended-baseline",
    "href": "error-recognition.html#recommended-baseline",
    "title": "Error Recognition",
    "section": "Recommended Baseline",
    "text": "Recommended Baseline\n\nGlobal-shutter camera (CSI or USB3) + fixed-focus lens covering the hook area + diffuse LED lighting.\nLock exposure/white balance; disable auto features.\nOptional GPIO trigger to align exposure with hook phase."
  },
  {
    "objectID": "error-recognition.html#recovery-hmi",
    "href": "error-recognition.html#recovery-hmi",
    "title": "Error Recognition",
    "section": "Recovery & HMI",
    "text": "Recovery & HMI\n\nOn detection: pause motion at safe phase, highlight ROI capture, show probable cause and guided steps (e.g., re-thread).\nOperator tools: snapshot, slow-motion replay (last 0.5‚Äì1.0 s), one-click retry."
  },
  {
    "objectID": "error-recognition.html#roadmap",
    "href": "error-recognition.html#roadmap",
    "title": "Error Recognition",
    "section": "Roadmap",
    "text": "Roadmap\n\nPhase 1: classical vision baseline (edges + region stats).\nPhase 2: lightweight CNN for robustness to yarn/lighting variants.\nPhase 3: multi-sensor fusion (tension + vision) and predictive alarms."
  },
  {
    "objectID": "error-recognition.html#choose-a-topic",
    "href": "error-recognition.html#choose-a-topic",
    "title": "Error Recognition",
    "section": "",
    "text": "üëâ Acquisition System (Camera)\nRequirements, sensor & lens selection, lighting, sync, and mounting constraints.\nüíª Error Recognition ‚Äî Code\nAlgorithms, model/code structure, data flow, and deployment notes.\nüß© 3D Camera Mount\nMechanical support, rigidity, vibration damping, working distance, and CAD notes.\nüìà Results & Efficiency\nDatasets, metrics (F1, latency, false alarms), ablation studies, and runtime budget."
  },
  {
    "objectID": "error-recognition.html#selection-of-the-acquisition-system-for-error-detection",
    "href": "error-recognition.html#selection-of-the-acquisition-system-for-error-detection",
    "title": "Error Recognition",
    "section": "- Selection of the Acquisition System for Error Detection",
    "text": "- Selection of the Acquisition System for Error Detection\nRequirements, sensor & lens selection, lighting, sync, and mounting constraints."
  },
  {
    "objectID": "error-recognition.html#error-recognition-code",
    "href": "error-recognition.html#error-recognition-code",
    "title": "Error Recognition",
    "section": "- Error Recognition ‚Äî Code",
    "text": "- Error Recognition ‚Äî Code\nAlgorithms, model/code structure, data flow, and deployment notes."
  },
  {
    "objectID": "error-recognition.html#d-camera-mount",
    "href": "error-recognition.html#d-camera-mount",
    "title": "Error Recognition",
    "section": "- 3D Camera Mount",
    "text": "- 3D Camera Mount\nMechanical support, 3D printing, working distance, and CAD notes."
  },
  {
    "objectID": "error-recognition.html#results-efficiency",
    "href": "error-recognition.html#results-efficiency",
    "title": "Error Recognition",
    "section": "- Results & Efficiency",
    "text": "- Results & Efficiency\nDatasets, metrics (F1, latency, false alarms), ablation studies, and runtime budget."
  },
  {
    "objectID": "error-camera.html",
    "href": "error-camera.html",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "",
    "text": "The goal of the system is to ensure automatic monitoring of the knitting process at each hook movement.\nA micro switch provides a synchronization signal, allowing the vision system to verify that the yarn (regardless of its color, thickness, or texture) is correctly positioned around the base of the hook.\nIn particular, the yarn should take on a ‚ÄúU‚Äù-shaped configuration embracing the base of the hook.\nAny configuration that does not match this pattern must be detected as an error.\nWhen an anomaly is detected, the system should:\n\nImmediately stop the motor driving the process;\n\nDisplay an error message and indicate the index of the corresponding hook.\n\nInsert example photo here."
  },
  {
    "objectID": "error-camera.html#objectives",
    "href": "error-camera.html#objectives",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "",
    "text": "The goal of the system is to ensure automatic monitoring of the knitting process at each hook movement.\nA micro switch provides a synchronization signal, allowing the vision system to verify that the yarn (regardless of its color, thickness, or texture) is correctly positioned around the base of the hook.\nIn particular, the yarn should take on a ‚ÄúU‚Äù-shaped configuration embracing the base of the hook.\nAny configuration that does not match this pattern must be detected as an error.\nWhen an anomaly is detected, the system should:\n\nImmediately stop the motor driving the process;\n\nDisplay an error message and indicate the index of the corresponding hook.\n\nInsert example photo here."
  },
  {
    "objectID": "error-camera.html#requirements",
    "href": "error-camera.html#requirements",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "Requirements",
    "text": "Requirements\nTo meet these objectives, the choice of camera and acquisition system must satisfy the following requirements:\n\nCompatibility with Raspberry Pi 3: use of natively supported interfaces and libraries.\n\nEase of software integration: availability of well-established computer vision libraries (e.g., libcamera, Picamera2, OpenCV).\n\nCost-effectiveness: a sensor with sufficient resolution to distinguish fine yarn details, while keeping costs low.\n\nClose-focus capability: ability to capture sharp images at short distances, near the hook area.\n\nCompact dimensions: a small camera module to facilitate mechanical integration within the machine‚Äôs 3D frame.\n\nLow power consumption: efficient power usage to minimize the overall system load."
  },
  {
    "objectID": "error-recognition.html#from-tradition-to-automation",
    "href": "error-recognition.html#from-tradition-to-automation",
    "title": "Error Recognition",
    "section": "",
    "text": "The first step toward automating such an ancient and traditional technique is the ability to detect production errors in real time.\nAn integrated vision system must be able to identify the occurrence of anomalies (for example, missing yarn or skipped stitches), allowing the machine to intervene and stop the process before the defect fully develops, preventing serious errors and material waste."
  },
  {
    "objectID": "index.html#selection-of-the-acquisition-system-for-error-detection",
    "href": "index.html#selection-of-the-acquisition-system-for-error-detection",
    "title": "Automated Knitting Machine",
    "section": "- Selection of the Acquisition System for Error Detection",
    "text": "- Selection of the Acquisition System for Error Detection\nRequirements, sensor & lens selection, lighting, sync, and mounting constraints."
  },
  {
    "objectID": "index.html#error-recognition-code",
    "href": "index.html#error-recognition-code",
    "title": "Automated Knitting Machine",
    "section": "- Error Recognition ‚Äî Code",
    "text": "- Error Recognition ‚Äî Code\nAlgorithms, model/code structure, data flow, and deployment notes."
  },
  {
    "objectID": "index.html#d-camera-mount",
    "href": "index.html#d-camera-mount",
    "title": "Automated Knitting Machine",
    "section": "- 3D Camera Mount",
    "text": "- 3D Camera Mount\nMechanical support, 3D printing, working distance, and CAD notes."
  },
  {
    "objectID": "index.html#results-efficiency",
    "href": "index.html#results-efficiency",
    "title": "Automated Knitting Machine",
    "section": "- Results & Efficiency",
    "text": "- Results & Efficiency\nDatasets, metrics (F1, latency, false alarms), ablation studies, and runtime budget."
  },
  {
    "objectID": "index.html#components",
    "href": "index.html#components",
    "title": "Automated Knitting Machine",
    "section": "- Components",
    "text": "- Components"
  },
  {
    "objectID": "index.html#errore",
    "href": "index.html#errore",
    "title": "Automated Knitting Machine",
    "section": "- Errore",
    "text": "- Errore\nRequirements, sensor & lens selection, lighting, sync, and mounting constraints."
  },
  {
    "objectID": "index.html#error-recognition",
    "href": "index.html#error-recognition",
    "title": "Automated Knitting Machine",
    "section": "- Error recognition",
    "text": "- Error recognition"
  },
  {
    "objectID": "index.html#control-s",
    "href": "index.html#control-s",
    "title": "Automated Knitting Machine",
    "section": "- Control S",
    "text": "- Control S\nMechanical support, 3D printing, working distance, and CAD notes."
  },
  {
    "objectID": "index.html#control-system",
    "href": "index.html#control-system",
    "title": "Automated Knitting Machine",
    "section": "- Control System",
    "text": "- Control System"
  },
  {
    "objectID": "error-camera.html#considered-architectures",
    "href": "error-camera.html#considered-architectures",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "Considered Architectures",
    "text": "Considered Architectures\nThis section describes the image acquisition options evaluated for the error detection system on Raspberry Pi 3, highlighting their implications in terms of image quality, latency, software integration, and overall system complexity.\n\nPi Camera via CSI Interface (recommended choice)\nThe Raspberry Pi Camera v2.1 connects to the Broadcom SoC through the MIPI-CSI interface, a high-speed differential serial bus dedicated to video capture.\nThis direct connection offers several advantages:\n\nHigh bandwidth and low latency: the pixel stream reaches the processor without passing through the USB or network stack, resulting in lower jitter and more deterministic timing.\n\nSuperior image quality: 8 MP sensor with the Raspberry platform‚Äôs integrated ISP, providing fine control over exposure, gain, white balance, and frame rate.\n\nNative integration: direct support via libcamera/Picamera2 and V4L2, with robust pipelines for OpenCV, TFLite, and other vision frameworks.\n\nImplications: a better signal-to-noise ratio and frame consistency lead to improved accuracy in detecting subtle defects.\nThe low latency facilitates synchronized triggering with the microswitch event.\n\n\n\nESP32-CAM via Wi-Fi or Serial\nThe ESP32-CAM integrates an OV2640 sensor (2 MP) and a microcontroller with Wi-Fi connectivity.\nTypical acquisition involves onboard JPEG/MJPEG compression and frame transmission:\n\nWi-Fi: sends frames or snapshots to a broker/server; wiring is simple, but latency and jitter depend on network conditions and buffering.\n\nSerial/USB-UART: sends data in chunks to the Raspberry Pi. It reduces network uncertainty but requires fragmentation/reassembly protocols and buffer management.\n\nImplications: extremely low cost and stand-alone operation, but lower image quality and controllability compared to CSI.\nCompression may hide fine defects, and the less deterministic timing makes it harder to align precisely with the hook‚Äôs motion.\nMoreover, the ESP32-CAM module is bulkier than the Pi Camera, making integration into the existing mechanical frame more difficult.\nOn the positive side, its shorter minimum focus distance makes it potentially more suitable for close-up shots without additional lenses.\n\nSerial Variant Experiment (unsuccessful)\nIn preliminary tests with a direct USB‚ÄìUART connection, the module was successfully flashed with a MicroPython firmware, but upon reboot, the board remained stuck in the bootloader. The serial output only produced unreadable characters or repetitive error messages, never reaching the REPL prompt. This prevented validation of direct communication with the Raspberry Pi.\n\n\nMQTT Variant Experiment (unsuccessful)\nWithin the Wi-Fi setup, a connection from ESP32-CAM ‚Üí Raspberry Pi was attempted via an MQTT broker, following a snapshot-based approach:\n\nThe ESP32-CAM captures a JPEG frame every few seconds and publishes it to an MQTT topic.\n\nThe Raspberry Pi, running a Mosquitto broker, subscribes to the topic, decodes the images, and displays/saves them locally.\n\nDespite the theoretical simplicity of this architecture, the practical tests were unsuccessful.\nIn particular, transmission and decoding issues occurred with the JPEG payloads (published directly via MQTT), making it impossible to correctly reconstruct the images on the Raspberry Pi side.\nGiven these early failures and adopting an agile development approach (iterative and adaptive, as opposed to a waterfall model), the decision was made not to continue integrating the ESP32-CAM through this method, favoring more reliable solutions consistent with the project requirements.\nConclusion: the ESP32-CAM via MQTT approach proved too unreliable for real-time error detection, further reinforcing the preference for the Pi Camera connected via CSI.\n\n\n\n\nOther Considered Alternatives (not tested)\n\nUSB Webcam\nA ready-to-use and widely available solution with UVC support.\nHowever, the data path goes through the USB stack, adding overhead compared to CSI and limiting camera control.\nIt can be suitable for prototyping or when latency requirements are less strict.\n\n\nRaspberry Pi HQ Camera\nA 12 MP module with a C/CS mount for interchangeable lenses.\nIt offers superior optical quality and flexibility (focus adjustment, focal lengths, dedicated macro optics) at the cost of higher price and larger size. Recommended when extreme close-ups or professional optical control are required."
  },
  {
    "objectID": "error-camera.html#error-recognition-code",
    "href": "error-camera.html#error-recognition-code",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "- Error Recognition ‚Äî Code",
    "text": "- Error Recognition ‚Äî Code\nAlgorithms, model/code structure, data flow, and deployment notes."
  },
  {
    "objectID": "error-camera.html#d-camera-mount",
    "href": "error-camera.html#d-camera-mount",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "- 3D Camera Mount",
    "text": "- 3D Camera Mount\nMechanical support, 3D printing, working distance, and CAD notes."
  },
  {
    "objectID": "error-camera.html#results-efficiency",
    "href": "error-camera.html#results-efficiency",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "- Results & Efficiency",
    "text": "- Results & Efficiency\nDatasets, metrics (F1, latency, false alarms), ablation studies, and runtime budget."
  },
  {
    "objectID": "error-camera.html#results-efficiency-1",
    "href": "error-camera.html#results-efficiency-1",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "- Results & Efficiency",
    "text": "- Results & Efficiency\nDatasets, metrics (F1, latency, false alarms), ablation studies, and runtime budget."
  },
  {
    "objectID": "error-camera.html#o",
    "href": "error-camera.html#o",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "- O",
    "text": "- O\nDatasets, metrics (F1, latency, false alarms), ablation studies, and runtime budget."
  },
  {
    "objectID": "error-camera.html#over",
    "href": "error-camera.html#over",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "- Over",
    "text": "- Over\nDatasets, metrics (F1, latency, false alarms), ablation studies, and runtime budget."
  },
  {
    "objectID": "error-camera.html#overview",
    "href": "error-camera.html#overview",
    "title": "Selection of the Acquisition System for Error Detection on a Raspberry Pi 3 model B+",
    "section": "- Overview",
    "text": "- Overview"
  }
]